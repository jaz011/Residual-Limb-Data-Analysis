{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This comment is a test to see how modified files work in Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named plotly.plotly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a6935f9b042e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotly\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named plotly.plotly"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.tools as tls\n",
    "from plotly import tools\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loads the data sets from the excel files and categorizes them\n",
    "df_good1 = pd.read_csv('./goodfit1.csv')\n",
    "df_good2 = pd.read_csv('./goodfit2.csv')\n",
    "df_good3 = pd.read_csv('./goodfit3.csv')\n",
    "df_poor1 = pd.read_csv('./poorfit1.csv')\n",
    "df_poor2 = pd.read_csv('./poorfit2.csv')\n",
    "df_poor3 = pd.read_csv('./poorfit3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_poor3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extracting the dataset into a matrix containing the temperature data and an array containing the class information\n",
    "X_g1 = df_good1.ix[:,1:9].values\n",
    "y_g1 = df_good1.ix[:,9].values\n",
    "X_g2 = df_good2.ix[:,1:9].values\n",
    "y_g2 = df_good2.ix[:,9].values\n",
    "X_g3 = df_good3.ix[:,1:9].values\n",
    "y_g3 = df_good3.ix[:,9].values\n",
    "X_p1 = df_poor1.ix[:,1:9].values\n",
    "y_p1 = df_poor1.ix[:,9].values\n",
    "X_p2 = df_poor2.ix[:,1:9].values\n",
    "y_p2 = df_poor2.ix[:,9].values\n",
    "X_p3 = df_poor3.ix[:,1:9].values\n",
    "y_p3 = df_poor3.ix[:,9].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we standardize the data points before feeding them into the PCA algorithm:\n",
    "Xg1_std = StandardScaler().fit_transform(X_g1)\n",
    "Xg2_std = StandardScaler().fit_transform(X_g2)\n",
    "Xg3_std = StandardScaler().fit_transform(X_g3)\n",
    "Xp1_std = StandardScaler().fit_transform(X_p1)\n",
    "Xp2_std = StandardScaler().fit_transform(X_p2)\n",
    "Xp3_std = StandardScaler().fit_transform(X_p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigendecomposition - Computing Eigenvectors and Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance Matrix, Eigenvectors, and Eigenvalues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eigendecomp(X_std):\n",
    "    \n",
    "    cov_mat = np.cov(X_std.T)\n",
    "#     print('Covariance matrix \\n%s' %cov_mat)\n",
    "\n",
    "    eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "#     print('Eigenvectors \\n%s' %eig_vecs)\n",
    "#     print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "    return eig_vals, eig_vecs\n",
    "eig_vals_g1, eig_vecs_g1 = eigendecomp(Xg1_std)\n",
    "eig_vals_g2, eig_vecs_g2 = eigendecomp(Xg2_std)\n",
    "eig_vals_g3, eig_vecs_g3 = eigendecomp(Xg3_std)\n",
    "eig_vals_p1, eig_vecs_p1 = eigendecomp(Xp1_std)\n",
    "eig_vals_p2, eig_vecs_p2 = eigendecomp(Xp2_std)\n",
    "eig_vals_p3, eig_vecs_p3 = eigendecomp(Xp3_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical goal of a PCA is to reduce the dimensionality of the original feature space by projecting it onto a smaller subspace, where the eigenvectors will form the axes. However, the eigenvectors only define the directions of the new axis, since they have all the same unit length 1, which can confirmed by the following two lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ev in eig_vecs_g1:\n",
    "    np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
    "print('Everything ok!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eigensort(eig_vals, eig_vecs):\n",
    "    # Make a list of (eigenvalue, eigenvector) tuples\n",
    "    eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "    # Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "    eig_pairs.sort()\n",
    "    eig_pairs.reverse()\n",
    "\n",
    "    # Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "    print('Eigenvalues in descending order:')\n",
    "    for i in eig_pairs:\n",
    "        print(i[0])\n",
    "    return eig_pairs\n",
    "eig_pairs_g1 = eigensort(eig_vals_g1, eig_vecs_g1)\n",
    "eig_pairs_g2 = eigensort(eig_vals_g2, eig_vecs_g2)\n",
    "eig_pairs_g3 = eigensort(eig_vals_g3, eig_vecs_g3)\n",
    "eig_pairs_p1 = eigensort(eig_vals_p1, eig_vecs_p1)\n",
    "eig_pairs_p2 = eigensort(eig_vals_p2, eig_vecs_p2)\n",
    "eig_pairs_p3 = eigensort(eig_vals_p3, eig_vecs_p3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explained Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sorting the eigenpairs, the next question is \"how many principal components are we going to choose for our new feature subspace?\" A useful measure is the so-called \"explained variance,\" which can be calculated from the eigenvalues. The explained variance tells us how much information (variance) can be attributed to each of the principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def explainedVar(eig_vals):\n",
    "    tot = sum(eig_vals_g1)\n",
    "    var_exp = [(i / tot)*100 for i in sorted(eig_vals_g1, reverse=True)]\n",
    "    return var_exp\n",
    "varexp_g1 = explainedVar(eig_vals_g1); varexp_g2 = explainedVar(eig_vals_g2);varexp_g3 = explainedVar(eig_vals_g3);\n",
    "varexp_p1 = explainedVar(eig_vals_p1); varexp_p2 = explainedVar(eig_vals_p2);varexp_p3 = explainedVar(eig_vals_p3);\n",
    "# cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "trace1 = go.Bar(\n",
    "        x=['PC %s' %i for i in range(1,9)],\n",
    "        y=varexp_g1,\n",
    "        showlegend=True)\n",
    "trace2 = go.Bar(\n",
    "        x=['PC %s' %i for i in range(1,9)],\n",
    "        y=varexp_g2,\n",
    "        showlegend=False)\n",
    "trace3 = go.Bar(\n",
    "        x=['PC %s' %i for i in range(1,9)],\n",
    "        y=varexp_g3,\n",
    "        showlegend=False)\n",
    "trace4 = go.Bar(\n",
    "        x=['PC %s' %i for i in range(1,9)],\n",
    "        y=varexp_p1,\n",
    "        showlegend=False)\n",
    "trace5 = go.Bar(\n",
    "        x=['PC %s' %i for i in range(1,9)],\n",
    "        y=varexp_p2,\n",
    "        showlegend=False)\n",
    "trace6 = Bar(\n",
    "        x=['PC %s' %i for i in range(1,9)],\n",
    "        y=varexp_p3,\n",
    "        showlegend=False)\n",
    "\n",
    "# trace2 = Scatter(\n",
    "#         x=['PC %s' %i for i in range(1,9)], \n",
    "#         y=cum_var_exp,\n",
    "#         name='cumulative explained variance')\n",
    "\n",
    "# data = Data([trace1, trace2])\n",
    "\n",
    "# layout=Layout(\n",
    "#         yaxis=YAxis(title='Explained variance in percent'),\n",
    "#         title='Explained variance by different principal components for the good fit trial 1')\n",
    "    \n",
    "fig = tools.make_subplots(rows=3, cols=2,\n",
    "                          subplot_titles=('good fit 1','poor fit 1','good fit 2', 'poor fit 2','good fit 3', 'poor fit 3'),\n",
    "                          specs=[[{}, {}], [{}, {}], [{}, {}]],\n",
    "                          horizontal_spacing = 0.1, vertical_spacing = 0.15)\n",
    "fig.append_trace(trace1, 1, 1)\n",
    "fig.append_trace(trace2, 2, 1)\n",
    "fig.append_trace(trace3, 3, 1)\n",
    "fig.append_trace(trace4, 1, 2)\n",
    "fig.append_trace(trace5, 2, 2)\n",
    "fig.append_trace(trace6, 3, 2)\n",
    "\n",
    "fig['layout']['yaxis1'].update(title='EV (%)')\n",
    "fig['layout']['yaxis2'].update(title='EV (%)')\n",
    "fig['layout']['yaxis3'].update(title='EV (%)')\n",
    "fig['layout']['yaxis4'].update(title='EV (%)')\n",
    "fig['layout']['yaxis5'].update(title='EV (%)')\n",
    "fig['layout']['yaxis6'].update(title='EV (%)')\n",
    "fig['layout'].update(title='Explained variance by different principal components')\n",
    "py.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, choosing two principal componnets with the highest eigenvalue will ensure that we save more than 95 percent of the data while reducing the dimension from nine to two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection Matrix and Projection Onto the New Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "Y1 = Xg1_std.dot(np.hstack((eig_pairs_g1[0][1].reshape(8,1), eig_pairs_g1[1][1].reshape(8,1))))\n",
    "Y2 = Xg2_std.dot(np.hstack((eig_pairs_g2[0][1].reshape(8,1), eig_pairs_g2[1][1].reshape(8,1))))\n",
    "Y3 = Xg3_std.dot(np.hstack((eig_pairs_g3[0][1].reshape(8,1), eig_pairs_g3[1][1].reshape(8,1))))\n",
    "Y4 = Xp1_std.dot(np.hstack((eig_pairs_p1[0][1].reshape(8,1), eig_pairs_p1[1][1].reshape(8,1))))\n",
    "Y5 = Xp2_std.dot(np.hstack((eig_pairs_p2[0][1].reshape(8,1), eig_pairs_p2[1][1].reshape(8,1))))\n",
    "Y6 = Xp3_std.dot(np.hstack((eig_pairs_p3[0][1].reshape(8,1), eig_pairs_p3[1][1].reshape(8,1))))\n",
    "# print('Matrix W:\\n', matrix_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will visualize the PCA results first for all the activities and then for the top three activities that are suspicious to play a key role in possible classification (walking on treadmill for two intervals and sit rest with px simulator doffed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " fig = tools.make_subplots(rows=3, cols=2,\n",
    "                           subplot_titles=('good fit 1','poor fit 1','good fit 2', 'poor fit 2','good fit 3', 'poor fit 3'),\n",
    "                           specs=[[{}, {}], [{}, {}], [{}, {}]],\n",
    "                           horizontal_spacing = 0.1, vertical_spacing = 0.15)\n",
    " i = 0\n",
    " clr = ['black','orange', 'blue','red','cyan','magenta','yellow','deeppink', 'firebrick']\n",
    " for name in ('don px components ', 'walk on treadmill (2)', 'walk on treadmill (1)', 'sit rest with px simulator doffed', 'sit rest with px simulator donned (3)', 'sit rest bare limb', 'doff px components', 'sit rest with px simulator donned (2)',\n",
    "              'sit rest with px simulator donned (1)'):\n",
    "    \n",
    "     trace1 = go.Scatter(\n",
    "         x=Y1[y_g1==name,0],\n",
    "         y=Y1[y_g1==name,1],\n",
    "         mode='markers',\n",
    "         name=name,\n",
    "         marker=dict(\n",
    "             size=3,\n",
    "             color = clr[i],\n",
    "             opacity=0.8))\n",
    "     fig.append_trace(trace1, 1, 1)\n",
    "\n",
    "     trace2 = go.Scatter(\n",
    "         x=Y2[y_g2==name,0],\n",
    "         y=Y2[y_g2==name,1],\n",
    "         mode='markers',\n",
    "         name=name,\n",
    "         marker=dict(\n",
    "             size=3,\n",
    "             color = clr[i],\n",
    "             opacity=0.8))\n",
    "     fig.append_trace(trace2, 2, 1)\n",
    "    \n",
    "     trace3 = go.Scatter(\n",
    "         x=Y3[y_g3==name,0],\n",
    "         y=Y3[y_g3==name,1],\n",
    "         mode='markers',\n",
    "         name=name,\n",
    "         marker=dict(\n",
    "             size=3,\n",
    "             color = clr[i],\n",
    "             opacity=0.8))\n",
    "     fig.append_trace(trace3, 3, 1)\n",
    "    \n",
    "     trace4 = go.Scatter(\n",
    "         x=Y4[y_p1==name,0],\n",
    "         y=Y4[y_p1==name,1],\n",
    "         mode='markers',\n",
    "         name=name,\n",
    "         marker=dict(\n",
    "             size=3,\n",
    "             color = clr[i],\n",
    "             opacity=0.8))\n",
    "     fig.append_trace(trace4, 1, 2)\n",
    "    \n",
    "     trace5 = go.Scatter(\n",
    "         x=Y5[y_p2==name,0],\n",
    "         y=Y5[y_p2==name,1],\n",
    "         mode='markers',\n",
    "         name=name,\n",
    "         marker=dict(\n",
    "             size=3,\n",
    "             color = clr[i]))\n",
    "     fig.append_trace(trace5, 2, 2)\n",
    "    \n",
    "     trace6 = go.Scatter(\n",
    "         x=Y6[y_p3==name,0],\n",
    "         y=Y6[y_p3==name,1],\n",
    "         mode='markers',\n",
    "         name=name,\n",
    "         marker=dict(\n",
    "             size=3,\n",
    "             color = clr[i],\n",
    "             opacity=0.8))\n",
    "     fig.append_trace(trace6, 3, 2)\n",
    "     i += 1\n",
    "\n",
    "\n",
    " fig['layout'].update(title='PC1 VS PC2 for all the activities')\n",
    "\n",
    "# py.iplot(fig)\n",
    "\n",
    "#from IPython.display import Image\n",
    "#Image('first.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# fig = tools.make_subplots(rows=3, cols=2,\n",
    "#                           subplot_titles=('good fit 1','poor fit 1','good fit 2', 'poor fit 2','good fit 3', 'poor fit 3'),\n",
    "#                           specs=[[{}, {}], [{}, {}], [{}, {}]],\n",
    "#                           horizontal_spacing = 0.1, vertical_spacing = 0.15)\n",
    "# i = 0\n",
    "# clr = ['black','orange', 'blue','red','cyan','magenta','yellow','deeppink', 'firebrick']\n",
    "\n",
    "# for name in ('walk on treadmill (2)', 'walk on treadmill (1)', 'sit rest with px simulator doffed'):\n",
    "    \n",
    "#     trace1 = go.Scatter(\n",
    "#         x=Y1[y_g1==name,0],\n",
    "#         y=Y1[y_g1==name,1],\n",
    "#         mode='markers',\n",
    "#         name=name,\n",
    "#         marker=dict(\n",
    "#             size=1,\n",
    "#             color = clr[i],\n",
    "#             opacity=0.8))\n",
    "#     fig.append_trace(trace1, 1, 1)\n",
    "\n",
    "#     trace2 = go.Scatter(\n",
    "#         x=Y2[y_g2==name,0],\n",
    "#         y=Y2[y_g2==name,1],\n",
    "#         mode='markers',\n",
    "#         name=name,\n",
    "#         marker=dict(\n",
    "#             size=1,\n",
    "#             color = clr[i],\n",
    "#             opacity=0.8))\n",
    "#     fig.append_trace(trace2, 2, 1)\n",
    "    \n",
    "#     trace3 = go.Scatter(\n",
    "#         x=Y3[y_g3==name,0],\n",
    "#         y=Y3[y_g3==name,1],\n",
    "#         mode='markers',\n",
    "#         name=name,\n",
    "#         marker=dict(\n",
    "#             size=1,\n",
    "#             color = clr[i],\n",
    "#             opacity=0.8))\n",
    "#     fig.append_trace(trace3, 3, 1)\n",
    "    \n",
    "#     trace4 = go.Scatter(\n",
    "#         x=Y4[y_p1==name,0],\n",
    "#         y=Y4[y_p1==name,1],\n",
    "#         mode='markers',\n",
    "#         name=name,\n",
    "#         marker=dict(\n",
    "#             size=1,\n",
    "#             color = clr[i],\n",
    "#             opacity=0.8))\n",
    "#     fig.append_trace(trace4, 1, 2)\n",
    "    \n",
    "#     trace5 = go.Scatter(\n",
    "#         x=Y5[y_p2==name,0],\n",
    "#         y=Y5[y_p2==name,1],\n",
    "#         mode='markers',\n",
    "#         name=name,\n",
    "#         marker=dict(\n",
    "#             size=1,\n",
    "#             color = clr[i]))\n",
    "#     fig.append_trace(trace5, 2, 2)\n",
    "    \n",
    "#     trace6 = go.Scatter(\n",
    "#         x=Y6[y_p3==name,0],\n",
    "#         y=Y6[y_p3==name,1],\n",
    "#         mode='markers',\n",
    "#         name=name,\n",
    "#         marker=dict(\n",
    "#             size=1,\n",
    "#             color = clr[i],\n",
    "#             opacity=0.8))\n",
    "#     fig.append_trace(trace6, 3, 2)\n",
    "#     i += 1\n",
    "\n",
    "# fig['layout'].update(title='PC1 VS PC2 for walking on treadmill and sit rest with px simulator doffed ')\n",
    "\n",
    "# py.iplot(fig)\n",
    "\n",
    "Image('second.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# fig = tools.make_subplots(rows=3, cols=2,\n",
    "#                           subplot_titles=('good fit 1','poor fit 1','good fit 2', 'poor fit 2','good fit 3', 'poor fit 3'),\n",
    "#                           specs=[[{}, {}], [{}, {}], [{}, {}]],\n",
    "#                           horizontal_spacing = 0.1, vertical_spacing = 0.15)\n",
    "# i = 0\n",
    "# clr = ['black','orange', 'blue','red','cyan','magenta','yellow','deeppink', 'firebrick']\n",
    "\n",
    "# for name in ('walk on treadmill (2)', 'walk on treadmill (1)', 'sit rest with px simulator doffed'):\n",
    "    \n",
    "#     trace1 = go.Scatter(\n",
    "#         x=np.mean(Y1[y_g1==name,0]),\n",
    "#         y=np.mean(Y1[y_g1==name,1]),\n",
    "#         mode='markers',\n",
    "#         name=name,\n",
    "#         marker=dict(\n",
    "#             size=10,\n",
    "#             color = clr[i],\n",
    "#             opacity=0.8))\n",
    "#     fig.append_trace(trace1, 1, 1)\n",
    "\n",
    "#     trace2 = go.Scatter(\n",
    "#         x=np.mean(Y2[y_g2==name,0]),\n",
    "#         y=np.mean(Y2[y_g2==name,1]),\n",
    "#         mode='markers',\n",
    "#         name=name,\n",
    "#         marker=dict(\n",
    "#             size=10,\n",
    "#             color = clr[i],\n",
    "#             opacity=0.8))\n",
    "#     fig.append_trace(trace2, 2, 1)\n",
    "    \n",
    "#     trace3 = go.Scatter(\n",
    "#         x=np.mean(Y3[y_g3==name,0]),\n",
    "#         y=np.mean(Y3[y_g3==name,1]),\n",
    "#         mode='markers',\n",
    "#         name=name,\n",
    "#         marker=dict(\n",
    "#             size=10,\n",
    "#             color = clr[i],\n",
    "#             opacity=0.8))\n",
    "#     fig.append_trace(trace3, 3, 1)\n",
    "    \n",
    "#     trace4 = go.Scatter(\n",
    "#         x=np.mean(Y4[y_p1==name,0]),\n",
    "#         y=np.mean(Y4[y_p1==name,1]),\n",
    "#         mode='markers',\n",
    "#         name=name,\n",
    "#         marker=dict(\n",
    "#             size=10,\n",
    "#             color = clr[i],\n",
    "#             opacity=0.8))\n",
    "#     fig.append_trace(trace4, 1, 2)\n",
    "    \n",
    "#     trace5 = go.Scatter(\n",
    "#         x=np.mean(Y5[y_p2==name,0]),\n",
    "#         y=np.mean(Y5[y_p2==name,1]),\n",
    "#         mode='markers',\n",
    "#         name=name,\n",
    "#         marker=dict(\n",
    "#             size=10,\n",
    "#             color = clr[i]))\n",
    "#     fig.append_trace(trace5, 2, 2)\n",
    "    \n",
    "#     trace6 = go.Scatter(\n",
    "#         x=np.mean(Y6[y_p3==name,0]),\n",
    "#         y=np.mean(Y6[y_p3==name,1]),\n",
    "#         mode='markers',\n",
    "#         name=name,\n",
    "#         marker=dict(\n",
    "#             size=10,\n",
    "#             color = clr[i],\n",
    "#             opacity=0.8))\n",
    "#     fig.append_trace(trace6, 3, 2)\n",
    "#     i += 1\n",
    "\n",
    "# fig['layout'].update(title='Calculated means on PC1 VS PC2 for walking on treadmill and sit rest with px simulator doffed ')\n",
    "\n",
    "# py.iplot(fig)\n",
    "\n",
    "Image('third.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Fourier transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fast Fourier transform (FFT) algorithm computes the discrete Fourier transform (DFT) of a sequence, or its inverse. Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa. An FFT rapidly computes such transformations by factorizing the DFT matrix into a product of sparse (mostly zero) factors.[1] As a result, it manages to reduce the complexity of computing the DFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we visualize the data first over the activities with the highest noise level ( taking into account that the dataset is averaged over different location in order to ease the process of visualization), then we compare the FFT output among different trials for possible classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fftpack\n",
    "\n",
    "y1 = np.mean(df_good1[df_good1['Class']== 'walk on treadmill (1)'].ix[:,1:9].values, axis = 1)\n",
    "y2 = np.mean(df_good2[df_good2['Class']== 'walk on treadmill (1)'].ix[:,1:9].values, axis = 1)\n",
    "y3 = np.mean(df_good3[df_good3['Class']== 'walk on treadmill (1)'].ix[:,1:9].values, axis = 1)\n",
    "y4 = np.mean(df_poor1[df_poor1['Class']== 'walk on treadmill (1)'].ix[:,1:9].values, axis = 1)\n",
    "y5 = np.mean(df_poor2[df_poor2['Class']== 'walk on treadmill (1)'].ix[:,1:9].values, axis = 1)\n",
    "y6 = np.mean(df_poor3[df_poor3['Class']== 'walk on treadmill (1)'].ix[:,1:9].values, axis = 1)\n",
    "\n",
    "x1 = df_good1[df_good1['Class']== 'walk on treadmill (1)'].ix[:,0].values\n",
    "x2 = df_good2[df_good2['Class']== 'walk on treadmill (1)'].ix[:,0].values\n",
    "x3 = df_good3[df_good3['Class']== 'walk on treadmill (1)'].ix[:,0].values\n",
    "x4 = df_poor1[df_poor1['Class']== 'walk on treadmill (1)'].ix[:,0].values\n",
    "x5 = df_poor2[df_poor2['Class']== 'walk on treadmill (1)'].ix[:,0].values\n",
    "x6 = df_poor3[df_poor3['Class']== 'walk on treadmill (1)'].ix[:,0].values\n",
    "\n",
    "\n",
    "def fft(y):\n",
    "    Fs = 150.0;  # sampling rate\n",
    "    Ts = 1.0/Fs; # sampling interval\n",
    "    #t = np.arange(0,1,Ts) # time vector\n",
    "\n",
    "\n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(n/2)] # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(n/2)]\n",
    "    return Y, frq\n",
    "y1f, frq1 = fft(y1)\n",
    "y2f, frq2 = fft(y2)\n",
    "y3f, frq3 = fft(y3)\n",
    "y4f, frq4 = fft(y4)\n",
    "y5f, frq5 = fft(y5)\n",
    "y6f, frq6 = fft(y6)\n",
    "trace1 = go.Scatter(\n",
    "        x=x1,\n",
    "        y=y1)\n",
    "trace2 = go.Scatter(\n",
    "        x=x2,\n",
    "        y=y2)\n",
    "trace3 = go.Scatter(\n",
    "        x=x3,\n",
    "        y=y3)\n",
    "trace4 = go.Scatter(\n",
    "        x=x4,\n",
    "        y=y4)\n",
    "trace5 = go.Scatter(\n",
    "        x=x5,\n",
    "        y=y5)\n",
    "trace6 = go.Scatter(\n",
    "        x=x6,\n",
    "        y=y6)\n",
    "fig = tools.make_subplots(rows=3, cols=2,\n",
    "                          subplot_titles=('good fit 1','poor fit 1','good fit 2', 'poor fit 2','good fit 3', 'poor fit 3'),\n",
    "                          specs=[[{}, {}], [{}, {}], [{}, {}]],\n",
    "                          horizontal_spacing = 0.1, vertical_spacing = 0.15)\n",
    "fig.append_trace(trace1, 1, 1)\n",
    "fig.append_trace(trace2, 2, 1)\n",
    "fig.append_trace(trace3, 3, 1)\n",
    "fig.append_trace(trace4, 1, 2)\n",
    "fig.append_trace(trace5, 2, 2)\n",
    "fig.append_trace(trace6, 3, 2)\n",
    "\n",
    "fig['layout'].update(title='Original averaged signal over all 8 locations in the first walking on treadmill activity')\n",
    "\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(321)\n",
    "ax1.plot(frq1[1:], abs(y1f)[1:], 'r-')\n",
    "ax1.set_title('good fit 1')\n",
    "ax2 = fig.add_subplot(322)\n",
    "ax2.plot(frq4[1:], abs(y4f)[1:], 'k-')\n",
    "ax2.set_title('poor fit 1')\n",
    "ax3 = fig.add_subplot(323)\n",
    "ax3.plot(frq2[1:], abs(y2f)[1:], 'b-')\n",
    "ax3.set_title('good fit 2')\n",
    "ax4 = fig.add_subplot(324)\n",
    "ax4.plot(frq5[1:], abs(y5f)[1:], 'g-')\n",
    "ax4.set_title('poor fit 2')                \n",
    "ax5 = fig.add_subplot(325)\n",
    "ax5.plot(frq3[1:], abs(y3f)[1:], 'g-')\n",
    "ax5.set_title('good fit 3')\n",
    "ax6 = fig.add_subplot(326)\n",
    "ax6.plot(frq6[1:], abs(y6f)[1:], 'g-')\n",
    "ax6.set_title('poor fit 3')\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()\n",
    "\n",
    "plotly_fig = tls.mpl_to_plotly( fig )\n",
    "plotly_fig['layout']['title'] = 'FFT for all trials on first walking period(Amplitude VS Freq)'\n",
    "plotly_fig['layout']['margin'].update({'t':50})\n",
    "py.iplot(plotly_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Above analysis was also performed on the second walking period and both revealed no significant difference among the datasets. Note:(It would be a good idea to run this individually on different locations without calculating the average)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
